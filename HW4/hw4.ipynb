{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW4, Jordan Gittleman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import gtsam\n",
    "import gtsam.utils.plot\n",
    "import itertools\n",
    "\n",
    "%matplotlib tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "siftPts = namedtuple('siftPts', 'k d')\n",
    "def siftDC(img):\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    img = clahe.apply(img)\n",
    "    # take in source and destinatition photos and outputs sift detected key points and computed descriptors as an array\n",
    "    sift = cv2.SIFT_create(nfeatures=4000,\n",
    "                                   nOctaveLayers=6,\n",
    "                                   contrastThreshold=0.025,\n",
    "                                   sigma=1.5) #create our detector\n",
    "    keypoints, descriptors = sift.detectAndCompute(img,None) # detect keypoints and compute descriptors\n",
    "\n",
    "    return siftPts(keypoints,descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchMaker(d1,d2,pts):\n",
    "    # takes in keypoints and descriptors for two images and returns a sorted index of matches using bfmatcher\n",
    "    # bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "    # matches = bf.match(d1,d2)\n",
    "    # matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(d1,d2, k=2)\n",
    "    xmatches = bf.knnMatch(d2,d1, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    goodmatch = 0\n",
    "    ratio = 0.01\n",
    "    while goodmatch <= pts:\n",
    "        for m in matches:\n",
    "            if m[0].distance < ratio*m[1].distance :\n",
    "                good.append(m[0])\n",
    "                goodmatch +=1\n",
    "        ratio += .05\n",
    "\n",
    "    good = sorted(good, key = lambda x:x.distance)\n",
    "\n",
    "    return matches, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getFun(dest_kp, src_kp,good): # find fundamental matrix, works in much the same way as finding H\n",
    "\n",
    "    dest = np.array([dest_kp[mat.queryIdx].pt for mat in good])\n",
    "    src = np.array([src_kp[mat.trainIdx].pt for mat in good])\n",
    "    p = np.array([0,0,0,0,0,0,0,0,1])    \n",
    "\n",
    "    F, mask = cv2.findFundamentalMat(dest,src,cv2.FM_RANSAC)\n",
    "    return F, mask, src, dest\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start by making a function to load in our images and detect features, storing what we find for later\n",
    "Graphbin = namedtuple('Graphbin', 'im pts')\n",
    "def gtloader(folder):\n",
    "    im_paths = []\n",
    "    for file in os.listdir(folder):\n",
    "        if \".png\" in file:\n",
    "            im_paths.append(os.path.join(folder,file))\n",
    "            # print(im_paths)\n",
    "\n",
    "    # now lets find features for each image and put them in a list\n",
    "    imgsAndPts=[]\n",
    "    im_paths.sort()\n",
    "    for image in im_paths:\n",
    "        img = cv2.imread(image)\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (0,0), fx=1, fy=1)\n",
    "        imgsAndPts.append(Graphbin(img,siftDC(img)))\n",
    "\n",
    "    im_height, im_width = img.shape[:2]\n",
    "    # get center point of image, this is our \"pose\"\n",
    "    cam_matrix = np.array([[1, 0, im_width/2], \n",
    "                          [0, 1, im_height/2],\n",
    "                          [0, 0, 1]])\n",
    "\n",
    "    return imgsAndPts, cam_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "buddha,cam_matrix=gtloader(\"./buddha_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121), plt.imshow(buddha[4].im)\n",
    "plt.subplot(122), plt.imshow(buddha[5].im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.72998736e-07 -3.53425706e-06  5.59279736e-03]\n",
      " [ 2.57045415e-06  3.08850905e-07  2.58121019e-02]\n",
      " [-5.42634073e-03 -2.72500202e-02  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "matches, good = matchMaker(buddha[1].pts.d,buddha[2].pts.d,500)\n",
    "imgLeft = buddha[1].im\n",
    "imgRight = buddha[2].im\n",
    "\n",
    "F, mask, ptsLeft, ptsRight= getFun(buddha[1].pts.k,buddha[2].pts.k,good)\n",
    "print(F)\n",
    "ptsLeft = np.int32(ptsLeft)\n",
    "ptsRight = np.int32(ptsRight)\n",
    "# We select only inlier points\n",
    "ptsLeft = ptsLeft[mask.ravel() == 1]\n",
    "ptsRight = ptsRight[mask.ravel() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawlines(img1, img2, lines, pts1, pts2):\n",
    "\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    r, c = img1.shape\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n",
    "      \n",
    "    for r, pt1, pt2 in zip(lines, pts1, pts2):\n",
    "          \n",
    "        color = tuple(np.random.randint(0, 255,\n",
    "                                        3).tolist())\n",
    "          \n",
    "        x0, y0 = map(int, [0, -r[2] / r[1] ])\n",
    "        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1] ])\n",
    "          \n",
    "        img1 = cv2.line(img1, \n",
    "                        (x0, y0), (x1, y1), color, 1)\n",
    "        img1 = cv2.circle(img1,\n",
    "                          tuple(pt1), 5, color, -1)\n",
    "        img2 = cv2.circle(img2, \n",
    "                          tuple(pt2), 5, color, -1)\n",
    "    return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find epilines corresponding to points\n",
    "# in right image (second image) and\n",
    "# drawing its lines on left image\n",
    "linesLeft = cv2.computeCorrespondEpilines(ptsRight.reshape(-1,\n",
    "                                                           1,\n",
    "                                                           2),\n",
    "                                          2, F)\n",
    "linesLeft = linesLeft.reshape(-1, 3)\n",
    "img5, img6 = drawlines(imgLeft, imgRight, \n",
    "                       linesLeft, ptsLeft,\n",
    "                       ptsRight)\n",
    "   \n",
    "# Find epilines corresponding to \n",
    "# points in left image (first image) and\n",
    "# drawing its lines on right image\n",
    "linesRight = cv2.computeCorrespondEpilines(ptsLeft.reshape(-1, 1, 2), \n",
    "                                           1, F)\n",
    "linesRight = linesRight.reshape(-1, 3)\n",
    "  \n",
    "img3, img4 = drawlines(imgRight, imgLeft, \n",
    "                       linesRight, ptsRight,\n",
    "                       ptsLeft)\n",
    "   \n",
    "plt.subplot(121), plt.imshow(img5)\n",
    "plt.subplot(122), plt.imshow(img3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps: fund mat -> essential -> recover pose -> projection mat -> triangulate pts\n",
    "essential=cam_matrix.transpose()@F@cam_matrix\n",
    "\n",
    "essential=cv2.findEssentialMat(ptsLeft,ptsRight,cam_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.11146655e-06 -4.39507497e-04 -2.37332336e-01]\n",
      " [ 4.27626965e-04  2.80416206e-06 -6.66087966e-01]\n",
      " [ 2.25549857e-01  6.70169434e-01 -8.37621613e-06]]\n"
     ]
    }
   ],
   "source": [
    "print(essential[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, R, t, mask = cv2.recoverPose(essential[0], ptsLeft, ptsRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.41990625e-01]\n",
      " [-3.35638613e-01]\n",
      " [ 6.19176444e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotCamera(R,t,ax,scale=.5,depth=.5,faceColor='grey'):\n",
    "    C = -t #camera center (in world coordinate system)\n",
    "\n",
    "    #Generating camera coordinate axes\n",
    "    axes = np.zeros((3,6))\n",
    "    axes[0,1], axes[1,3],axes[2,5] = 1,1,1\n",
    "    \n",
    "    #Transforming to world coordinate system \n",
    "    axes = R.T.dot(axes)+C[:,np.newaxis]\n",
    "\n",
    "    #Plotting axes\n",
    "    ax.plot3D(xs=axes[0,:2],ys=axes[1,:2],zs=axes[2,:2],c='r')\n",
    "    ax.plot3D(xs=axes[0,2:4],ys=axes[1,2:4],zs=axes[2,2:4],c='g')\n",
    "    ax.plot3D(xs=axes[0,4:],ys=axes[1,4:],zs=axes[2,4:],c='b')\n",
    "\n",
    "    #generating 5 corners of camera polygon \n",
    "    pt1 = np.array([[0,0,0]]).T #camera centre\n",
    "    pt2 = np.array([[scale,-scale,depth]]).T #upper right \n",
    "    pt3 = np.array([[scale,scale,depth]]).T #lower right \n",
    "    pt4 = np.array([[-scale,-scale,depth]]).T #upper left\n",
    "    pt5 = np.array([[-scale,scale,depth]]).T #lower left\n",
    "    pts = np.concatenate((pt1,pt2,pt3,pt4,pt5),axis=-1)\n",
    "    \n",
    "    #Transforming to world-coordinate system\n",
    "    pts = R.T.dot(pts)+C[:,np.newaxis]\n",
    "    ax.scatter3D(xs=pts[0,:],ys=pts[1,:],zs=pts[2,:],c='k')\n",
    "    \n",
    "    #Generating a list of vertices to be connected in polygon\n",
    "    verts = [[pts[:,0],pts[:,1],pts[:,2]], [pts[:,0],pts[:,2],pts[:,-1]],\n",
    "            [pts[:,0],pts[:,-1],pts[:,-2]],[pts[:,0],pts[:,-2],pts[:,1]]]\n",
    "    \n",
    "    #Generating a polygon now..\n",
    "    ax.add_collection3d(Poly3DCollection(verts, facecolors=faceColor,\n",
    "                                         linewidths=1, edgecolors='k', alpha=.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "#for initial camera\n",
    "R1=np.eye(3)\n",
    "t1=np.array([0,0,0])\n",
    "print(t1)\n",
    "PlotCamera(R1,t1,ax)\n",
    "PlotCamera(R,t.T[0],ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turtlechip():\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #for initial camera\n",
    "    R1=np.eye(3)\n",
    "    t1=np.array([0,0,0])\n",
    "    PlotCamera(R1,t1,ax)\n",
    "\n",
    "    for i in range(len(buddha)-1):\n",
    "        print(i)\n",
    "        matches, good = matchMaker(buddha[i].pts.d,buddha[i+1].pts.d,4000)\n",
    "        imgLeft = buddha[i].im\n",
    "        imgRight = buddha[i+1].im\n",
    "\n",
    "\n",
    "        F, mask, ptsLeft, ptsRight= getFun(buddha[i].pts.k,buddha[i+1].pts.k,good)\n",
    "        ptsLeft = np.int32(ptsLeft)\n",
    "        ptsRight = np.int32(ptsRight)\n",
    "        # We select only inlier points\n",
    "        ptsLeft = ptsLeft[mask.ravel() == 1]\n",
    "        ptsRight = ptsRight[mask.ravel() == 1]\n",
    "        essential=cv2.findEssentialMat(ptsLeft,ptsRight,cam_matrix)\n",
    "        print(essential[0])\n",
    "        pts, R, t, mask = cv2.recoverPose(essential[0], ptsLeft, ptsRight)\n",
    "        # R1=np.matmul(R1,R)\n",
    "        t1=t1+t.T[0]\n",
    "        #for initial camera\n",
    "        PlotCamera(R1,t1,ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 5.63963761e-04 -3.40895139e-02  2.83375380e-01]\n",
      " [ 3.42035171e-02  3.47860303e-04 -6.46942869e-01]\n",
      " [ 2.94129277e-01 -6.42120565e-01  2.28929828e-04]]\n",
      "1\n",
      "[[-9.90698055e-06  4.48403359e-04  2.45055721e-01]\n",
      " [-4.58706422e-04 -4.30197906e-06  6.63285743e-01]\n",
      " [-2.36261861e-01 -6.66468033e-01 -2.20997587e-06]]\n",
      "2\n",
      "[[ 1.71794199e-05 -9.28518181e-04 -1.68386291e-01]\n",
      " [ 8.97111305e-04  2.13298563e-05 -6.86764334e-01]\n",
      " [ 1.50063839e-01  6.90999264e-01 -1.00527320e-05]]\n",
      "3\n",
      "[[-1.07101795e-05  5.08486273e-04  9.08461996e-02]\n",
      " [-5.29224321e-04 -1.33783681e-05 -7.01246524e-01]\n",
      " [-1.09283100e-01  6.98610725e-01  3.24952151e-06]]\n",
      "4\n",
      "[[-2.54231270e-05 -6.14509749e-04 -5.20415298e-01]\n",
      " [ 6.68158203e-04 -1.17908658e-05  4.78714423e-01]\n",
      " [ 5.26900577e-01 -4.71566935e-01 -5.47171472e-05]]\n",
      "5\n",
      "[[-1.57088456e-05  2.90904834e-04 -1.11272728e-01]\n",
      " [-3.23388618e-04 -1.55043708e-05 -6.98296696e-01]\n",
      " [ 8.57050178e-02  7.01893557e-01 -8.76568338e-06]]\n",
      "6\n",
      "[[-1.08424000e-07  3.83609686e-04  2.24960742e-01]\n",
      " [-3.99912400e-04 -1.20877117e-05 -6.70367439e-01]\n",
      " [-2.35886388e-01  6.66601430e-01  6.10444883e-07]]\n",
      "7\n",
      "[[ 8.26155189e-07 -5.28992059e-05 -6.52549424e-03]\n",
      " [ 3.37372192e-05 -3.82810310e-06 -7.07076670e-01]\n",
      " [-6.88563306e-03  7.07073253e-01 -4.64449779e-06]]\n",
      "8\n",
      "[[ 9.22295266e-06 -7.34324484e-04  7.54066848e-02]\n",
      " [ 7.10907411e-04  2.58029013e-05 -7.03074194e-01]\n",
      " [-8.20550362e-02  7.02329292e-01  2.13511079e-05]]\n",
      "9\n",
      "[[-1.15752762e-04 -1.78243782e-02  5.40261893e-01]\n",
      " [ 1.77253362e-02  1.34932788e-04 -4.55846942e-01]\n",
      " [ 5.39799101e-01 -4.56405142e-01 -5.57145713e-05]]\n",
      "10\n",
      "[[ 7.94923384e-07 -1.21202405e-04  2.99823384e-01]\n",
      " [ 1.05626094e-04  2.72267288e-05 -6.40395131e-01]\n",
      " [-2.97251030e-01  6.41593183e-01  2.89317030e-05]]\n",
      "11\n",
      "[[ 3.46427682e-06  9.66213614e-05  2.05508233e-01]\n",
      " [-1.22392876e-04  1.11236012e-05 -6.76584327e-01]\n",
      " [-2.25887604e-01  6.70055803e-01  2.12085821e-05]]\n",
      "12\n",
      "[[ 3.13146969e-06 -4.95505068e-04 -5.49050317e-01]\n",
      " [ 4.38905440e-04 -3.33881681e-05 -4.45582211e-01]\n",
      " [ 5.40095574e-01  4.56395192e-01 -4.88024685e-05]]\n",
      "13\n",
      "[[ 9.34538291e-06  5.25058768e-04 -4.02838044e-01]\n",
      " [-5.13957320e-04 -4.17114226e-05  5.81137863e-01]\n",
      " [ 4.05203030e-01 -5.79491377e-01 -2.81314972e-05]]\n",
      "14\n",
      "[[ 5.03826251e-07  3.66946426e-02  7.05686265e-01]\n",
      " [-3.67721162e-02 -7.58064078e-04 -2.56586575e-02]\n",
      " [ 7.06063331e-01 -1.11022576e-02 -7.61571895e-04]]\n",
      "15\n",
      "[[-4.90737290e-07 -3.72348542e-04 -2.03762944e-01]\n",
      " [ 3.44944718e-04  3.53321794e-07 -6.77111913e-01]\n",
      " [ 1.90669697e-01  6.80914774e-01 -1.39674972e-05]]\n",
      "16\n",
      "[[ 1.35290574e-06 -8.42135438e-04 -4.93015658e-01]\n",
      " [ 8.16855471e-04  8.46570472e-06 -5.06887442e-01]\n",
      " [ 4.82299228e-01  5.17094536e-01 -2.49039522e-05]]\n",
      "17\n",
      "[[ 3.34365696e-06 -5.62946999e-04 -3.44754864e-01]\n",
      " [ 5.45316588e-04  5.27613208e-06 -6.17368433e-01]\n",
      " [ 3.32211254e-01  6.24207793e-01 -1.37732070e-05]]\n",
      "18\n",
      "[[ 5.56533229e-06 -4.65134304e-04  2.62757029e-02]\n",
      " [ 4.60073674e-04  6.30563225e-06 -7.06618267e-01]\n",
      " [-3.44447633e-02  7.06267189e-01  1.17174339e-06]]\n",
      "19\n",
      "[[ 3.39372403e-06  1.42485843e-04  5.12817135e-01]\n",
      " [-1.41881097e-04 -5.72625418e-06  4.86845527e-01]\n",
      " [-5.07125398e-01 -4.92771559e-01  9.71952903e-07]]\n",
      "20\n",
      "[[ 6.81172009e-07  2.38803966e-04  3.87793760e-02]\n",
      " [-2.62880255e-04  3.39992985e-06  7.06042557e-01]\n",
      " [-4.47157044e-02 -7.05691467e-01 -1.38125158e-07]]\n"
     ]
    }
   ],
   "source": [
    "pts=turtlechip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTriangulatedPts(img1pts,img2pts,K,R,t): \n",
    "    img1ptsHom = cv2.convertPointsToHomogeneous(img1pts)[:,0,:]\n",
    "    img2ptsHom = cv2.convertPointsToHomogeneous(img2pts)[:,0,:]\n",
    "\n",
    "    img1ptsNorm = (np.linalg.inv(K).dot(img1ptsHom.T)).T\n",
    "    img2ptsNorm = (np.linalg.inv(K).dot(img2ptsHom.T)).T\n",
    "\n",
    "    img1ptsNorm = cv2.convertPointsFromHomogeneous(img1ptsNorm)[:,0,:]\n",
    "    img2ptsNorm = cv2.convertPointsFromHomogeneous(img2ptsNorm)[:,0,:]\n",
    "\n",
    "    pts4d = cv2.triangulatePoints(np.eye(3,4),np.hstack((R,t)),img1ptsNorm.T,img2ptsNorm.T)\n",
    "    pts3d = cv2.convertPointsFromHomogeneous(pts4d.T)[:,0,:]\n",
    "\n",
    "    return pts3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptsv2=GetTriangulatedPts(ptsLeft,ptsRight,cam_matrix,R,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fa114ad3fd0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(ptsv2[:,0], ptsv2[:,1], ptsv2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f32c342d9ea7f5036db09204dae45f5252a65bc883a367b7eae2cb473c9503d1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('afr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
