{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the pointLoad function loads in the specified image and prompts to hand pick a set amount of points. TODO: store points for future runs to disable popup's and embed images for ease of documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointLoad(imgpath,pts = 0, imgpass = True):\n",
    "\n",
    "    if os.path.exists(imgpath):\n",
    "        img = cv2.imread(imgpath)\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if pts:\n",
    "            ptMatrix = pointPick(img,pts)\n",
    "            # plt.close()\n",
    "            if imgpass:\n",
    "                return img, np.array(ptMatrix).astype(int)\n",
    "            else:\n",
    "                return np.array(ptMatrix).astype(int)    \n",
    "        else:\n",
    "            return img\n",
    "    else:\n",
    "        print(\"Invalid image path\")\n",
    "        return\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pointPick(img,pts):\n",
    "    plt.imshow(img)\n",
    "    ptMatrix = plt.ginput(pts)\n",
    "    return ptMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getH creates a homography matrix between the source and destination photos, instead of using svd, I opted to construct the matrix with an explicit final h33 param = 1 and use least squares, something svd does internally anyway but I want to be difficult..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getH(dest, src):\n",
    "    p = np.array([0,0,0,0,0,0,0,0,1])\n",
    "    # if len(dest) < 5 and len(src) < 5:\n",
    "        \n",
    "\n",
    "    for i in range(len(dest)):\n",
    "        pi = np.array([[-src[i][0],-src[i][1],-1,0,0,0,src[i][0]*dest[i][0],src[i][1]*dest[i][0],dest[i][0]],\n",
    "        [0,0,0,-src[i][0],-src[i][1],-1,src[i][0]*dest[i][1],src[i][1]*dest[i][1],dest[i][1]]])\n",
    "        p = np.vstack((pi,p))\n",
    "\n",
    "  \n",
    "    x = np.zeros((len(dest)*2,1))\n",
    "    x = np.vstack((x,np.array([1])))\n",
    "    H, residuals, rank, s = np.linalg.lstsq(p,x)\n",
    "    H = H.reshape((3,3))\n",
    "    \n",
    "\n",
    "    \n",
    "    return H\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function to paste the source image onto the destination, the implementation itself is a little hack-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pasteImages(img1,img1pts,img2,img2pts):\n",
    "    H = getH(img1pts,img2pts)\n",
    "    im_out = cv2.warpPerspective(img2,H,(img1.shape[1],img1.shape[0]))\n",
    "    mask = np.zeros(img1.shape[:2], dtype=\"uint8\")\n",
    "    cv2.fillConvexPoly(mask, np.int32([img1pts]),color=255)\n",
    "    cv2.fillConvexPoly(img1, np.int32([img1pts]),color=0)\n",
    "    masked =cv2.bitwise_and(im_out,im_out,mask=mask)\n",
    "    img3 = cv2.add(img1,masked)\n",
    "    # img3=cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
    "    return img3, H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract 4 points from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1, img1pts = pointLoad(\"image1.jpg\",4)\n",
    "\n",
    "img2, img2pts = pointLoad(\"image2.jpg\",4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paste the images together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img3, H3 = pasteImages(img1,img1pts,img2,img2pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and display..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(img3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process can also be repeated with as many points as youd like due to the getH function performing least squares on the images, here we will do just that with 8 points from each image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1New, img1ptsNew = pointLoad(\"image1.jpg\",8)\n",
    "img2New, img2ptsNew = pointLoad(\"image2.jpg\",8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3New, H3New = pasteImages(img1New,img1ptsNew,img2New,img2ptsNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img3New)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can compare the two H matrix's and see how they differ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H3)\n",
    "print(\"~~~~\")\n",
    "print(H3New)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, both Homographies differ while still yielding similar transoformations. In part, this is due to my bad clicking accuracy between images. A more major factor however, is that the transofrms are scaled differently.\n",
    "If you observe the value at h33, the scale factors differ wildly, given that that h33 = wk where w is an arbitrary scale factor and k is 1. This difference for us does not matter fortunately as these transformations are scale invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets perform this 8 point homography again but for a new image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img4, img4pts = pointLoad(\"image3.jpg\",8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img5, H5 = pasteImages(img1New,img1ptsNew,img4,img4pts)\n",
    "\n",
    "plt.imshow(img5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try some panorama stitching. This will work in much the same way as before but with some extra complications for our final output image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# left={'pts':[],'h':[]}\n",
    "# right={'pts':[],'h':[]}\n",
    "# # get points/homographies for left-bound images\n",
    "# for n in [2,1]:\n",
    "#     destpts = pointLoad(image_paths[n],4,False)\n",
    "#     left['pts'].append(destpts)\n",
    "#     srcpts = pointLoad(image_paths[n-1],4,False)\n",
    "#     left['pts'].append(srcpts)\n",
    "#     left['h'].append(getH(destpts,srcpts))\n",
    "\n",
    "# for n in [2,3]:\n",
    "#     destpts = pointLoad(image_paths[n],4,False)\n",
    "#     right['pts'].append(destpts)\n",
    "#     srcpts = pointLoad(image_paths[n+1],4,False)\n",
    "#     right['pts'].append(srcpts)\n",
    "#     right['h'].append(getH(destpts,srcpts))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an array of the left homographies and of the right as well as points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any transforms, we need to relate our outer edges of the panorama to the central image (image 3). this could either be done by warping the outermost image to the one inner image and then warping those to the center.\n",
    "This method, however, is flawed as it will result in some drift from the error in the homographies.\n",
    "\n",
    "A better way to apraoch the edge images is to dot the outer homography with the inner to create a direct relation from the outer image to the central one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warpTwoImages(img1, img2, H):\n",
    "    '''warp img2 to img1 with homograph H'''\n",
    "    h1,w1 = img1.shape[:2]\n",
    "    h2,w2 = img2.shape[:2]\n",
    "    pts1 = np.float32([[0,0],[0,h1],[w1,h1],[w1,0]]).reshape(-1,1,2)\n",
    "    pts2 = np.float32([[0,0],[0,h2],[w2,h2],[w2,0]]).reshape(-1,1,2)\n",
    "    pts2_ = cv2.perspectiveTransform(pts2, H)\n",
    "    pts = np.concatenate((pts1, pts2_), axis=0)\n",
    "    [xmin, ymin] = np.int32(pts.min(axis=0).ravel() - 0.5)\n",
    "    [xmax, ymax] = np.int32(pts.max(axis=0).ravel() + 0.5)\n",
    "    t = [-xmin,-ymin]\n",
    "    Ht = np.array([[1,0,t[0]],[0,1,t[1]],[0,0,1]]) # translate\n",
    "\n",
    "    result = cv2.warpPerspective(img2, Ht.dot(H), (xmax-xmin, ymax-ymin))\n",
    "    result[t[1]:h1+t[1],t[0]:w1+t[0]] = img1\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35992/3460832648.py:14: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  H, residuals, rank, s = np.linalg.lstsq(p,x)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_paths=['i1.jpg','i2.jpg','i3.jpg','i4.jpg','i5.jpg']\n",
    "images=[]\n",
    "for image in image_paths:\n",
    "    img = pointLoad(image)\n",
    "    cv2.resize(img, (0,0), fx=.1, fy=.1)\n",
    "    images.append(img)\n",
    "trainImg=images[2]\n",
    "queryImg=images[1]\n",
    "width = trainImg.shape[1] + queryImg.shape[1]\n",
    "height = trainImg.shape[0] #+ queryImg.shape[0]\n",
    "\n",
    "result = cv2.warpPerspective(trainImg, getH(pointPick(trainImg,4),pointPick(queryImg,4)), (width, height))\n",
    "result[0:queryImg.shape[0], 0:queryImg.shape[1]] = queryImg\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.imshow(result)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# this is a super hack-y apprach, essentially, I am finding overlap points iterativly with each composite\n",
    "# super unsatisying apprach so this is still a WiP I want to approach properly\n",
    "# output1 =warpTwoImages(images[2],images[3],getH(pointPick(images[2],4),pointPick(images[3],4)))\n",
    "# output2 =warpTwoImages(output1,images[4],getH(pointPick(output1,4),pointPick(images[4],4)))\n",
    "# output3 =warpTwoImages(output2,images[1],getH(pointPick(output2,4),pointPick(images[1],4)))\n",
    "# output4 =warpTwoImages(output3,images[0],getH(pointPick(output3,4),pointPick(images[0],4)))\n",
    "# output2 =warpTwoImages(output1,images[3],(right['h'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f32c342d9ea7f5036db09204dae45f5252a65bc883a367b7eae2cb473c9503d1"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('afr': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
